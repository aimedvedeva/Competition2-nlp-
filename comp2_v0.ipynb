{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vNYx_VP20g-agF3xJr86134T_KaabHM-",
      "authorship_tag": "ABX9TyMG+DCoblKLlsYVgUDznioh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimedvedeva/Competition2-nlp-/blob/main/comp2_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mg12axzUWKJd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "prompts_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Comp2/prompts_train.csv\")\n",
        "summaries_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Comp2/summaries_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(prompts_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSOys8UwfM0v",
        "outputId": "9681cbb2-79be-46da-c803-9d5cd7e4a538"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(summaries_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnDLw1GEfQ6v",
        "outputId": "a55b0574-9ef9-43b5-e37c-59d3467aed63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7165"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df = pd.merge(summaries_df, prompts_df, how = 'left', on = 'prompt_id')"
      ],
      "metadata": {
        "id": "IfFETJUQWkfi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(combined_train_df) == len(summaries_df)"
      ],
      "metadata": {
        "id": "j7LB_afBWnBz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Ga_xygWqRE",
        "outputId": "b55586c8-2a35-459b-8019-70627601cd5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['student_id', 'prompt_id', 'text', 'content', 'wording',\n",
              "       'prompt_question', 'prompt_title', 'prompt_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LNbD4UmIWs95",
        "outputId": "e3c9fb3f-b3c4-4647-bcf6-e2b7dedff718"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           content      wording\n",
              "count  7165.000000  7165.000000\n",
              "mean     -0.014853    -0.063072\n",
              "std       1.043569     1.036048\n",
              "min      -1.729859    -1.962614\n",
              "25%      -0.799545    -0.872720\n",
              "50%      -0.093814    -0.081769\n",
              "75%       0.499660     0.503833\n",
              "max       3.900326     4.310693"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f97bc12a-86c2-4f60-9b58-159bb115f43a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7165.000000</td>\n",
              "      <td>7165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.014853</td>\n",
              "      <td>-0.063072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.043569</td>\n",
              "      <td>1.036048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.729859</td>\n",
              "      <td>-1.962614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.799545</td>\n",
              "      <td>-0.872720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.093814</td>\n",
              "      <td>-0.081769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.499660</td>\n",
              "      <td>0.503833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.900326</td>\n",
              "      <td>4.310693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f97bc12a-86c2-4f60-9b58-159bb115f43a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-00461003-f9c1-4dd6-9885-585eb7609b18\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00461003-f9c1-4dd6-9885-585eb7609b18')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-00461003-f9c1-4dd6-9885-585eb7609b18 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f97bc12a-86c2-4f60-9b58-159bb115f43a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f97bc12a-86c2-4f60-9b58-159bb115f43a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df[(combined_train_df['prompt_id'] == 'ebad26') & (combined_train_df['content'] < -1.4)].iloc[0]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qjRL8-LAWyLL",
        "outputId": "daa01b07-2458-4b07-b66c-362d821ff303"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'They would \"rub it up with soda to take away the smell, pickle it with a \"stronger pickle\" to remove the smell, and they would extract the bone and cook the inside to sell them as \"boneless hams\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df[(combined_train_df['prompt_id'] == 'ebad26') & (combined_train_df['content'] > 3.4)].iloc[0]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "KDOU8d0OW0T1",
        "outputId": "86f65ed6-8239-484c-f7c0-49a1825f008d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There were various things that the factory would do to cover up and essentially use the spoiled meat that they had. One manner in which they practiced this was by rubbing the meat with soda to take away the smell, as stated in paragraph two.  The workers would also pickle their meat to get rid of the odor but if it was very pungent, they had a second and much stronger pickle which helped destroy the smell, which the workers called, \"giving them thirty per cent.\" Along with this, they would label the packages in many ways to make it look like it was \"original\" even if they were made out of meat parts that were not supposed to be used. Another form in which they would use and cover-up spoiled meat would be by getting spoiled whole ham and old sausage with mold from Europe and dosing it with borax and glycerin, where it would then be dumped into hoppers and made over again for packaging. Mice, feces, poisoned bread, dirt, diseases, and sawdust were just a few things that would be processed in the hoppers along with the spoiled meat. Lastly, they would also use their chemistry department to make sausages appear brown-with the use of borax and colored gelatin- and labeled it \"smoked\" sausage after their practice of smoking sausage became expensive for the factory.  In all, the actions in which the factory practiced were extremely unsanitary and do not appear today thanks to the Meat Inspection Act. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate metrics"
      ],
      "metadata": {
        "id": "VjaHfkxeW-VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = combined_train_df['text'].tolist()\n",
        "prompt_texts = combined_train_df['prompt_text'].tolist()\n",
        "prompt_questions = combined_train_df['prompt_question'].tolist()"
      ],
      "metadata": {
        "id": "m9Eh6rKUXA0S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weIFIXw4fCdt",
        "outputId": "06401501-9ece-4043-814c-fff961ddf9b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['student_id', 'prompt_id', 'text', 'content', 'wording',\n",
              "       'prompt_question', 'prompt_title', 'prompt_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [BERTScore](https://huggingface.co/spaces/evaluate-metric/bertscore)\n",
        "\n",
        "\n",
        "> BERTScore leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference sentences by cosine similarity. It has been shown to correlate with human judgment on sentence-level and system-level evaluation. Moreover, BERTScore computes precision, recall, and F1 measure, which can be useful for evaluating different language generation tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "8r3GhYUUXdgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### pips"
      ],
      "metadata": {
        "id": "ieMM1hzGXcHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "id": "YQmQuTmOXEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bert_score"
      ],
      "metadata": {
        "id": "GRHfb_QEXGDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### calculation"
      ],
      "metadata": {
        "id": "KCdIOn0-XyR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")"
      ],
      "metadata": {
        "id": "tHTpzVbdYDzE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_scores = []\n",
        "for i in range(len(summaries)):\n",
        "  print(i)\n",
        "  score = bertscore.compute(predictions=[summaries[i]], references=[prompt_texts[i]], lang=\"en\")\n",
        "  print(score)\n",
        "  bert_scores.append(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Ef7mxsXzdE",
        "outputId": "073908d8-c725-4aa7-fb02-624c87970a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "{'precision': [0.8283703923225403], 'recall': [0.7932977080345154], 'f1': [0.8104547262191772], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "1\n",
            "{'precision': [0.8546106219291687], 'recall': [0.7895169258117676], 'f1': [0.8207751512527466], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "2\n",
            "{'precision': [0.8588669896125793], 'recall': [0.8438898324966431], 'f1': [0.851312518119812], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "3\n",
            "{'precision': [0.8455113768577576], 'recall': [0.7886843085289001], 'f1': [0.816109836101532], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "4\n",
            "{'precision': [0.8321478366851807], 'recall': [0.8212687969207764], 'f1': [0.8266725540161133], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "5\n",
            "{'precision': [0.8613998889923096], 'recall': [0.7893351912498474], 'f1': [0.8237944841384888], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "6\n",
            "{'precision': [0.8248896598815918], 'recall': [0.7874569892883301], 'f1': [0.8057387471199036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "7\n",
            "{'precision': [0.8429926633834839], 'recall': [0.7901170253753662], 'f1': [0.8156988024711609], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "8\n",
            "{'precision': [0.8552213311195374], 'recall': [0.7847933769226074], 'f1': [0.8184951543807983], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "9\n",
            "{'precision': [0.830816924571991], 'recall': [0.7786113619804382], 'f1': [0.8038673996925354], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "10\n",
            "{'precision': [0.7986905574798584], 'recall': [0.7700729966163635], 'f1': [0.7841207385063171], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "11\n",
            "{'precision': [0.8286870718002319], 'recall': [0.7951195240020752], 'f1': [0.811556339263916], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "12\n",
            "{'precision': [0.8425818681716919], 'recall': [0.8039370179176331], 'f1': [0.8228059411048889], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "13\n",
            "{'precision': [0.8554743528366089], 'recall': [0.7930764555931091], 'f1': [0.8230945467948914], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "14\n",
            "{'precision': [0.8571170568466187], 'recall': [0.8049670457839966], 'f1': [0.8302239179611206], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "15\n",
            "{'precision': [0.8480316400527954], 'recall': [0.7929728627204895], 'f1': [0.8195785880088806], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "16\n",
            "{'precision': [0.8349733352661133], 'recall': [0.8013873100280762], 'f1': [0.8178356885910034], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "17\n",
            "{'precision': [0.8546593189239502], 'recall': [0.8169077634811401], 'f1': [0.8353571891784668], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "18\n",
            "{'precision': [0.8650859594345093], 'recall': [0.8037014007568359], 'f1': [0.8332646489143372], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "19\n",
            "{'precision': [0.8572131395339966], 'recall': [0.79034024477005], 'f1': [0.8224195241928101], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "20\n",
            "{'precision': [0.8452329635620117], 'recall': [0.7832989692687988], 'f1': [0.8130882382392883], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "21\n",
            "{'precision': [0.7997466921806335], 'recall': [0.7795714139938354], 'f1': [0.7895302176475525], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "22\n",
            "{'precision': [0.8288797736167908], 'recall': [0.7777019143104553], 'f1': [0.8024756908416748], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "23\n",
            "{'precision': [0.8419336080551147], 'recall': [0.8251866698265076], 'f1': [0.8334760665893555], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "24\n",
            "{'precision': [0.8706384897232056], 'recall': [0.8218277096748352], 'f1': [0.8455291986465454], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "25\n",
            "{'precision': [0.9511416554450989], 'recall': [0.8232870101928711], 'f1': [0.88260817527771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "26\n",
            "{'precision': [0.8380411267280579], 'recall': [0.8074002265930176], 'f1': [0.8224354386329651], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "27\n",
            "{'precision': [0.8430114984512329], 'recall': [0.7859099507331848], 'f1': [0.8134598731994629], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "28\n",
            "{'precision': [0.8511740565299988], 'recall': [0.8079386353492737], 'f1': [0.8289929628372192], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "29\n",
            "{'precision': [0.8323144316673279], 'recall': [0.8042607307434082], 'f1': [0.8180471062660217], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "30\n",
            "{'precision': [0.8542402386665344], 'recall': [0.7912635803222656], 'f1': [0.8215467929840088], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "31\n",
            "{'precision': [0.8302329778671265], 'recall': [0.8028825521469116], 'f1': [0.8163287043571472], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "32\n",
            "{'precision': [0.8524646162986755], 'recall': [0.7826974391937256], 'f1': [0.8160926103591919], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "33\n",
            "{'precision': [0.8446339964866638], 'recall': [0.7917307615280151], 'f1': [0.8173272013664246], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "34\n",
            "{'precision': [0.8333626389503479], 'recall': [0.7987151145935059], 'f1': [0.8156710863113403], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "35\n",
            "{'precision': [0.8461860418319702], 'recall': [0.7795343399047852], 'f1': [0.8114938735961914], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "36\n",
            "{'precision': [0.8375948667526245], 'recall': [0.7897967100143433], 'f1': [0.8129938244819641], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "37\n",
            "{'precision': [0.8243260979652405], 'recall': [0.8092507123947144], 'f1': [0.8167188167572021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "38\n",
            "{'precision': [0.845782458782196], 'recall': [0.7974731922149658], 'f1': [0.8209176659584045], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "39\n",
            "{'precision': [0.8362575769424438], 'recall': [0.8129637241363525], 'f1': [0.8244461417198181], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "40\n",
            "{'precision': [0.8945772051811218], 'recall': [0.7999234795570374], 'f1': [0.8446066975593567], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "41\n",
            "{'precision': [0.8504719734191895], 'recall': [0.7826088666915894], 'f1': [0.815130352973938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "42\n",
            "{'precision': [0.8533388376235962], 'recall': [0.7901657223701477], 'f1': [0.8205381035804749], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "43\n",
            "{'precision': [0.9004056453704834], 'recall': [0.8081207275390625], 'f1': [0.85177081823349], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "44\n",
            "{'precision': [0.8647084832191467], 'recall': [0.7942442893981934], 'f1': [0.8279799222946167], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "45\n",
            "{'precision': [0.855425238609314], 'recall': [0.7847743630409241], 'f1': [0.8185781240463257], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "46\n",
            "{'precision': [0.850258469581604], 'recall': [0.7895283699035645], 'f1': [0.8187688589096069], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "47\n",
            "{'precision': [0.8380646705627441], 'recall': [0.8157020211219788], 'f1': [0.8267321586608887], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "48\n",
            "{'precision': [0.8760676980018616], 'recall': [0.7986871600151062], 'f1': [0.8355898261070251], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "49\n",
            "{'precision': [0.8725693821907043], 'recall': [0.7908369898796082], 'f1': [0.8296952247619629], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "50\n",
            "{'precision': [0.8553549647331238], 'recall': [0.7879506945610046], 'f1': [0.8202704787254333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "51\n",
            "{'precision': [0.8425590991973877], 'recall': [0.7890846133232117], 'f1': [0.8149455189704895], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "52\n",
            "{'precision': [0.8532586097717285], 'recall': [0.7747216820716858], 'f1': [0.8120957612991333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "53\n",
            "{'precision': [0.9158601760864258], 'recall': [0.8078991770744324], 'f1': [0.8584988117218018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "54\n",
            "{'precision': [0.8349894285202026], 'recall': [0.7948020696640015], 'f1': [0.814400315284729], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "55\n",
            "{'precision': [0.85963374376297], 'recall': [0.817525327205658], 'f1': [0.8380509614944458], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "56\n",
            "{'precision': [0.8265783786773682], 'recall': [0.7745800018310547], 'f1': [0.799734890460968], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "57\n",
            "{'precision': [0.8320059776306152], 'recall': [0.7816820740699768], 'f1': [0.8060593605041504], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "58\n",
            "{'precision': [0.8403443694114685], 'recall': [0.8163608312606812], 'f1': [0.8281790614128113], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "59\n",
            "{'precision': [0.8798975944519043], 'recall': [0.7881350517272949], 'f1': [0.8314922451972961], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "60\n",
            "{'precision': [0.8334835767745972], 'recall': [0.7875698208808899], 'f1': [0.8098764419555664], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "61\n",
            "{'precision': [0.8673367500305176], 'recall': [0.817598819732666], 'f1': [0.8417336940765381], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "62\n",
            "{'precision': [0.8438188433647156], 'recall': [0.8070989847183228], 'f1': [0.8250505924224854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "63\n",
            "{'precision': [0.8603408336639404], 'recall': [0.7921647429466248], 'f1': [0.8248463869094849], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "64\n",
            "{'precision': [0.8421133756637573], 'recall': [0.7811403274536133], 'f1': [0.8104817271232605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "65\n",
            "{'precision': [0.8707824349403381], 'recall': [0.8019186854362488], 'f1': [0.8349330425262451], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "66\n",
            "{'precision': [0.8148332238197327], 'recall': [0.7867538928985596], 'f1': [0.8005474805831909], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "67\n",
            "{'precision': [0.8229523301124573], 'recall': [0.7764136791229248], 'f1': [0.799005925655365], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "68\n",
            "{'precision': [0.8553386330604553], 'recall': [0.8488219976425171], 'f1': [0.8520678281784058], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "69\n",
            "{'precision': [0.8588359355926514], 'recall': [0.8013222813606262], 'f1': [0.8290828466415405], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "70\n",
            "{'precision': [0.8684828281402588], 'recall': [0.7930498719215393], 'f1': [0.829054057598114], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "71\n",
            "{'precision': [0.8427269458770752], 'recall': [0.8017544746398926], 'f1': [0.8217302560806274], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "72\n",
            "{'precision': [0.8428738117218018], 'recall': [0.7864059209823608], 'f1': [0.8136613368988037], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "73\n",
            "{'precision': [0.8494353890419006], 'recall': [0.7843782305717468], 'f1': [0.8156115412712097], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "74\n",
            "{'precision': [0.8849915266036987], 'recall': [0.7892020344734192], 'f1': [0.834356427192688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "75\n",
            "{'precision': [0.8181368112564087], 'recall': [0.7745498418807983], 'f1': [0.795746922492981], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "76\n",
            "{'precision': [0.8714226484298706], 'recall': [0.791170060634613], 'f1': [0.8293595314025879], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "77\n",
            "{'precision': [0.8426124453544617], 'recall': [0.7895820140838623], 'f1': [0.8152357339859009], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "78\n",
            "{'precision': [0.8540511131286621], 'recall': [0.7871485352516174], 'f1': [0.8192362785339355], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "79\n",
            "{'precision': [0.83232182264328], 'recall': [0.7993820905685425], 'f1': [0.8155195116996765], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "80\n",
            "{'precision': [0.8573035597801208], 'recall': [0.7736197710037231], 'f1': [0.8133147358894348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "81\n",
            "{'precision': [0.9004364609718323], 'recall': [0.799768328666687], 'f1': [0.8471221327781677], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "82\n",
            "{'precision': [0.8248483538627625], 'recall': [0.7791045904159546], 'f1': [0.8013242483139038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "83\n",
            "{'precision': [0.8524355292320251], 'recall': [0.7990726828575134], 'f1': [0.824891984462738], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "84\n",
            "{'precision': [0.867923378944397], 'recall': [0.7987747192382812], 'f1': [0.8319146633148193], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "85\n",
            "{'precision': [0.8430293798446655], 'recall': [0.7796264886856079], 'f1': [0.8100892305374146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "86\n",
            "{'precision': [0.8896218538284302], 'recall': [0.8088135719299316], 'f1': [0.847295343875885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "87\n",
            "{'precision': [0.8435310125350952], 'recall': [0.7921148538589478], 'f1': [0.8170148134231567], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "88\n",
            "{'precision': [0.8881323337554932], 'recall': [0.8013339638710022], 'f1': [0.8425034880638123], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "89\n",
            "{'precision': [0.9173316955566406], 'recall': [0.8236717581748962], 'f1': [0.8679823875427246], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "90\n",
            "{'precision': [0.8463866114616394], 'recall': [0.8311229348182678], 'f1': [0.8386853337287903], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "91\n",
            "{'precision': [0.8598923087120056], 'recall': [0.7878389954566956], 'f1': [0.8222902417182922], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "92\n",
            "{'precision': [0.8418402075767517], 'recall': [0.7886780500411987], 'f1': [0.8143925070762634], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "93\n",
            "{'precision': [0.8401764035224915], 'recall': [0.8000266551971436], 'f1': [0.8196101784706116], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "94\n",
            "{'precision': [0.8418520092964172], 'recall': [0.813274085521698], 'f1': [0.8273163437843323], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "95\n",
            "{'precision': [0.8461192846298218], 'recall': [0.7841047644615173], 'f1': [0.8139325380325317], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "96\n",
            "{'precision': [0.8320267200469971], 'recall': [0.7844117283821106], 'f1': [0.807517945766449], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "97\n",
            "{'precision': [0.8451993465423584], 'recall': [0.7858105897903442], 'f1': [0.814423680305481], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "98\n",
            "{'precision': [0.8326504826545715], 'recall': [0.8017078042030334], 'f1': [0.8168862462043762], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "99\n",
            "{'precision': [0.8811062574386597], 'recall': [0.7944568395614624], 'f1': [0.8355410695075989], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "100\n",
            "{'precision': [0.8442788124084473], 'recall': [0.7861194610595703], 'f1': [0.8141617774963379], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "101\n",
            "{'precision': [0.8576906323432922], 'recall': [0.8076150417327881], 'f1': [0.8319000005722046], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "102\n",
            "{'precision': [0.8774441480636597], 'recall': [0.8114832639694214], 'f1': [0.8431756496429443], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "103\n",
            "{'precision': [0.8915671110153198], 'recall': [0.8260433673858643], 'f1': [0.8575553894042969], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "104\n",
            "{'precision': [0.850448727607727], 'recall': [0.7816637754440308], 'f1': [0.814606785774231], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "105\n",
            "{'precision': [0.8737597465515137], 'recall': [0.8009401559829712], 'f1': [0.8357667922973633], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "106\n",
            "{'precision': [0.8485544323921204], 'recall': [0.7929463982582092], 'f1': [0.8198085427284241], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "107\n",
            "{'precision': [0.8324504494667053], 'recall': [0.81046062707901], 'f1': [0.8213083744049072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "108\n",
            "{'precision': [0.840104341506958], 'recall': [0.7896189093589783], 'f1': [0.8140796422958374], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "109\n",
            "{'precision': [0.8631285429000854], 'recall': [0.7926213145256042], 'f1': [0.8263737559318542], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "110\n",
            "{'precision': [0.8444391489028931], 'recall': [0.7970219254493713], 'f1': [0.8200456500053406], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "111\n",
            "{'precision': [0.8785673379898071], 'recall': [0.8288652300834656], 'f1': [0.8529928922653198], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "112\n",
            "{'precision': [0.8392629623413086], 'recall': [0.8212888240814209], 'f1': [0.8301786184310913], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "113\n",
            "{'precision': [0.82452392578125], 'recall': [0.7750082612037659], 'f1': [0.7989997267723083], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "114\n",
            "{'precision': [0.828434944152832], 'recall': [0.7950499653816223], 'f1': [0.8113992214202881], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "115\n",
            "{'precision': [0.8234809041023254], 'recall': [0.7925053238868713], 'f1': [0.8076962232589722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "116\n",
            "{'precision': [0.8724915385246277], 'recall': [0.808510422706604], 'f1': [0.8392834663391113], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "117\n",
            "{'precision': [0.8833596706390381], 'recall': [0.8005121350288391], 'f1': [0.839897871017456], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "118\n",
            "{'precision': [0.8958581686019897], 'recall': [0.8005257844924927], 'f1': [0.8455132246017456], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "119\n",
            "{'precision': [0.8353081941604614], 'recall': [0.7915400266647339], 'f1': [0.8128353357315063], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "120\n",
            "{'precision': [0.8470574021339417], 'recall': [0.7965060472488403], 'f1': [0.821004331111908], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "121\n",
            "{'precision': [0.8419207334518433], 'recall': [0.7930771112442017], 'f1': [0.8167693018913269], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "122\n",
            "{'precision': [0.8653402328491211], 'recall': [0.8331807255744934], 'f1': [0.8489560484886169], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "123\n",
            "{'precision': [0.8230271935462952], 'recall': [0.786812961101532], 'f1': [0.8045127391815186], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "124\n",
            "{'precision': [0.861163318157196], 'recall': [0.8033685088157654], 'f1': [0.8312625288963318], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "125\n",
            "{'precision': [0.8767954111099243], 'recall': [0.7902485132217407], 'f1': [0.8312754034996033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "126\n",
            "{'precision': [0.7972146272659302], 'recall': [0.7784495949745178], 'f1': [0.7877203226089478], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "127\n",
            "{'precision': [0.8507621884346008], 'recall': [0.845808207988739], 'f1': [0.8482779860496521], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "128\n",
            "{'precision': [0.8422068953514099], 'recall': [0.7785358428955078], 'f1': [0.8091206550598145], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "129\n",
            "{'precision': [0.8175534605979919], 'recall': [0.7778481841087341], 'f1': [0.797206699848175], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "130\n",
            "{'precision': [0.8235684037208557], 'recall': [0.7859684824943542], 'f1': [0.8043292760848999], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "131\n",
            "{'precision': [0.8488061428070068], 'recall': [0.8041797876358032], 'f1': [0.8258906006813049], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "132\n",
            "{'precision': [0.8325068950653076], 'recall': [0.7832876443862915], 'f1': [0.8071476221084595], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "133\n",
            "{'precision': [0.8578549027442932], 'recall': [0.7991891503334045], 'f1': [0.8274835348129272], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "134\n",
            "{'precision': [0.8520101308822632], 'recall': [0.8040810823440552], 'f1': [0.8273520469665527], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "135\n",
            "{'precision': [0.8159171342849731], 'recall': [0.7736155390739441], 'f1': [0.7942034602165222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "136\n",
            "{'precision': [0.8352243304252625], 'recall': [0.7857509851455688], 'f1': [0.8097326755523682], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "137\n",
            "{'precision': [0.872622549533844], 'recall': [0.8086010217666626], 'f1': [0.8393927812576294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "138\n",
            "{'precision': [0.8535746932029724], 'recall': [0.8247589468955994], 'f1': [0.838919460773468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "139\n",
            "{'precision': [0.8437085151672363], 'recall': [0.7936429381370544], 'f1': [0.8179102540016174], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "140\n",
            "{'precision': [0.8652747869491577], 'recall': [0.8473184704780579], 'f1': [0.8562024235725403], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "141\n",
            "{'precision': [0.8621254563331604], 'recall': [0.8070878982543945], 'f1': [0.8336993455886841], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "142\n",
            "{'precision': [0.8386657238006592], 'recall': [0.7828258872032166], 'f1': [0.8097842931747437], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "143\n",
            "{'precision': [0.844788670539856], 'recall': [0.7937498092651367], 'f1': [0.818474292755127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "144\n",
            "{'precision': [0.847922682762146], 'recall': [0.8166335225105286], 'f1': [0.8319839835166931], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "145\n",
            "{'precision': [0.864971399307251], 'recall': [0.7810313105583191], 'f1': [0.8208610415458679], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "146\n",
            "{'precision': [0.9050936102867126], 'recall': [0.81785649061203], 'f1': [0.8592665791511536], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "147\n",
            "{'precision': [0.8526965975761414], 'recall': [0.8074429631233215], 'f1': [0.8294529914855957], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "148\n",
            "{'precision': [0.8748583793640137], 'recall': [0.8125531077384949], 'f1': [0.8425554633140564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "149\n",
            "{'precision': [0.8697109818458557], 'recall': [0.8013005256652832], 'f1': [0.8341054916381836], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "150\n",
            "{'precision': [0.813857913017273], 'recall': [0.7847596406936646], 'f1': [0.7990439534187317], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "151\n",
            "{'precision': [0.8735949397087097], 'recall': [0.8233463764190674], 'f1': [0.8477267026901245], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "152\n",
            "{'precision': [0.8328993916511536], 'recall': [0.8071245551109314], 'f1': [0.8198094367980957], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "153\n",
            "{'precision': [0.8598425984382629], 'recall': [0.7828025817871094], 'f1': [0.8195160031318665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "154\n",
            "{'precision': [0.8399571180343628], 'recall': [0.7879793643951416], 'f1': [0.8131384253501892], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "155\n",
            "{'precision': [0.8500741720199585], 'recall': [0.7971159815788269], 'f1': [0.8227437734603882], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "156\n",
            "{'precision': [0.8143925070762634], 'recall': [0.7871676683425903], 'f1': [0.8005487322807312], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "157\n",
            "{'precision': [0.8574255704879761], 'recall': [0.7840631008148193], 'f1': [0.8191049098968506], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "158\n",
            "{'precision': [0.839453935623169], 'recall': [0.804378867149353], 'f1': [0.8215422034263611], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "159\n",
            "{'precision': [0.8294705152511597], 'recall': [0.7959644794464111], 'f1': [0.8123722076416016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "160\n",
            "{'precision': [0.9126511812210083], 'recall': [0.8023816347122192], 'f1': [0.8539714813232422], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "161\n",
            "{'precision': [0.8260485529899597], 'recall': [0.7953640818595886], 'f1': [0.8104159832000732], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "162\n",
            "{'precision': [0.8515439629554749], 'recall': [0.8037986755371094], 'f1': [0.8269827961921692], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "163\n",
            "{'precision': [0.8596587181091309], 'recall': [0.797558069229126], 'f1': [0.827444851398468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "164\n",
            "{'precision': [0.8172738552093506], 'recall': [0.7884681224822998], 'f1': [0.8026126027107239], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "165\n",
            "{'precision': [0.8601502180099487], 'recall': [0.8050017356872559], 'f1': [0.8316627144813538], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "166\n",
            "{'precision': [0.8405707478523254], 'recall': [0.7799736261367798], 'f1': [0.8091391921043396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "167\n",
            "{'precision': [0.8735442161560059], 'recall': [0.8307545185089111], 'f1': [0.8516122102737427], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "168\n",
            "{'precision': [0.8529043197631836], 'recall': [0.7948341965675354], 'f1': [0.8228460550308228], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "169\n",
            "{'precision': [0.863174319267273], 'recall': [0.8163910508155823], 'f1': [0.8391310572624207], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "170\n",
            "{'precision': [0.9121506214141846], 'recall': [0.8127449750900269], 'f1': [0.8595834374427795], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "171\n",
            "{'precision': [0.9054771065711975], 'recall': [0.8008389472961426], 'f1': [0.8499496579170227], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "172\n",
            "{'precision': [0.8379743695259094], 'recall': [0.7900891304016113], 'f1': [0.8133275508880615], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "173\n",
            "{'precision': [0.9183409214019775], 'recall': [0.7898904085159302], 'f1': [0.8492862582206726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "174\n",
            "{'precision': [0.833950400352478], 'recall': [0.7817795872688293], 'f1': [0.8070226311683655], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "175\n",
            "{'precision': [0.8443958759307861], 'recall': [0.816581130027771], 'f1': [0.8302556276321411], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "176\n",
            "{'precision': [0.8449108600616455], 'recall': [0.7852317690849304], 'f1': [0.8139788508415222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "177\n",
            "{'precision': [0.841768741607666], 'recall': [0.783772885799408], 'f1': [0.8117362260818481], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "178\n",
            "{'precision': [0.8517347574234009], 'recall': [0.7899510264396667], 'f1': [0.8196803331375122], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "179\n",
            "{'precision': [0.8911241292953491], 'recall': [0.8146701455116272], 'f1': [0.8511837720870972], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "180\n",
            "{'precision': [0.8156265020370483], 'recall': [0.7914096117019653], 'f1': [0.8033355474472046], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "181\n",
            "{'precision': [0.8739410638809204], 'recall': [0.8136715292930603], 'f1': [0.8427301049232483], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "182\n",
            "{'precision': [0.8576695322990417], 'recall': [0.8270138502120972], 'f1': [0.842062771320343], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "183\n",
            "{'precision': [0.8517850041389465], 'recall': [0.7848280668258667], 'f1': [0.8169368505477905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "184\n",
            "{'precision': [0.8267074227333069], 'recall': [0.807587206363678], 'f1': [0.8170354962348938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "185\n",
            "{'precision': [0.8790006637573242], 'recall': [0.8309493064880371], 'f1': [0.8542998433113098], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "186\n",
            "{'precision': [0.857190728187561], 'recall': [0.8391667604446411], 'f1': [0.848082959651947], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "187\n",
            "{'precision': [0.8642900586128235], 'recall': [0.8137902617454529], 'f1': [0.8382803201675415], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "188\n",
            "{'precision': [0.8504518270492554], 'recall': [0.7843509912490845], 'f1': [0.8160650730133057], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "189\n",
            "{'precision': [0.8256662487983704], 'recall': [0.8157669305801392], 'f1': [0.8206866979598999], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "190\n",
            "{'precision': [0.8486843109130859], 'recall': [0.8082261085510254], 'f1': [0.827961266040802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "191\n",
            "{'precision': [0.8411118984222412], 'recall': [0.7828549146652222], 'f1': [0.8109384775161743], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "192\n",
            "{'precision': [0.8592888116836548], 'recall': [0.8195432424545288], 'f1': [0.8389455676078796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "193\n",
            "{'precision': [0.8350529074668884], 'recall': [0.783881425857544], 'f1': [0.8086584210395813], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "194\n",
            "{'precision': [0.8786905407905579], 'recall': [0.8039835691452026], 'f1': [0.8396786451339722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "195\n",
            "{'precision': [0.8410181403160095], 'recall': [0.7948838472366333], 'f1': [0.8173004984855652], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "196\n",
            "{'precision': [0.838943600654602], 'recall': [0.7946721315383911], 'f1': [0.816208004951477], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "197\n",
            "{'precision': [0.8712560534477234], 'recall': [0.7912914752960205], 'f1': [0.8293506503105164], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "198\n",
            "{'precision': [0.8417569398880005], 'recall': [0.790835440158844], 'f1': [0.8155019879341125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "199\n",
            "{'precision': [0.847427487373352], 'recall': [0.7923438549041748], 'f1': [0.8189604878425598], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "200\n",
            "{'precision': [0.867597758769989], 'recall': [0.7870641946792603], 'f1': [0.8253712058067322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "201\n",
            "{'precision': [0.824260950088501], 'recall': [0.7737292051315308], 'f1': [0.7981961369514465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "202\n",
            "{'precision': [0.8685001730918884], 'recall': [0.7842884063720703], 'f1': [0.8242489099502563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "203\n",
            "{'precision': [0.8348278999328613], 'recall': [0.7971854209899902], 'f1': [0.8155725598335266], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "204\n",
            "{'precision': [0.8629140257835388], 'recall': [0.7895675897598267], 'f1': [0.824613094329834], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "205\n",
            "{'precision': [0.8691620826721191], 'recall': [0.8016647100448608], 'f1': [0.8340500593185425], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "206\n",
            "{'precision': [0.8871976733207703], 'recall': [0.8363018035888672], 'f1': [0.8609982132911682], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "207\n",
            "{'precision': [0.839232325553894], 'recall': [0.7817651629447937], 'f1': [0.8094800710678101], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "208\n",
            "{'precision': [0.8640540838241577], 'recall': [0.8239389657974243], 'f1': [0.8435198664665222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "209\n",
            "{'precision': [0.8544947504997253], 'recall': [0.7771809101104736], 'f1': [0.8140061497688293], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "210\n",
            "{'precision': [0.9277862310409546], 'recall': [0.8013691902160645], 'f1': [0.8599565625190735], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "211\n",
            "{'precision': [0.8735195994377136], 'recall': [0.7854198813438416], 'f1': [0.8271304368972778], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "212\n",
            "{'precision': [0.8768954277038574], 'recall': [0.8566627502441406], 'f1': [0.866661012172699], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "213\n",
            "{'precision': [0.862236499786377], 'recall': [0.8029488325119019], 'f1': [0.8315372467041016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "214\n",
            "{'precision': [0.8690741658210754], 'recall': [0.8239678740501404], 'f1': [0.8459201455116272], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "215\n",
            "{'precision': [0.8331606388092041], 'recall': [0.7817220687866211], 'f1': [0.8066221475601196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "216\n",
            "{'precision': [0.8831361532211304], 'recall': [0.7893964648246765], 'f1': [0.8336394429206848], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "217\n",
            "{'precision': [0.8351798057556152], 'recall': [0.7918558120727539], 'f1': [0.8129409551620483], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "218\n",
            "{'precision': [0.8346490859985352], 'recall': [0.7908461093902588], 'f1': [0.8121574521064758], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "219\n",
            "{'precision': [0.8291093111038208], 'recall': [0.786344587802887], 'f1': [0.8071608543395996], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "220\n",
            "{'precision': [0.8584854602813721], 'recall': [0.805823802947998], 'f1': [0.8313214778900146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "221\n",
            "{'precision': [0.8201255202293396], 'recall': [0.7894172072410583], 'f1': [0.8044784069061279], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "222\n",
            "{'precision': [0.8796830773353577], 'recall': [0.7868479490280151], 'f1': [0.8306797742843628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "223\n",
            "{'precision': [0.8297082185745239], 'recall': [0.8062713146209717], 'f1': [0.8178218603134155], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "224\n",
            "{'precision': [0.8497586250305176], 'recall': [0.7934301495552063], 'f1': [0.8206290006637573], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "225\n",
            "{'precision': [0.8651233315467834], 'recall': [0.803735077381134], 'f1': [0.8333001136779785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "226\n",
            "{'precision': [0.8447666168212891], 'recall': [0.7876049876213074], 'f1': [0.8151849508285522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "227\n",
            "{'precision': [0.8296169638633728], 'recall': [0.7856302857398987], 'f1': [0.8070246577262878], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "228\n",
            "{'precision': [0.9280486702919006], 'recall': [0.7856656908988953], 'f1': [0.8509422540664673], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "229\n",
            "{'precision': [0.8532566428184509], 'recall': [0.7942995429039001], 'f1': [0.8227232098579407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "230\n",
            "{'precision': [0.8392005562782288], 'recall': [0.7814791202545166], 'f1': [0.8093119263648987], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "231\n",
            "{'precision': [0.8225847482681274], 'recall': [0.7676042318344116], 'f1': [0.7941440343856812], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "232\n",
            "{'precision': [0.8532483577728271], 'recall': [0.7885456085205078], 'f1': [0.8196219801902771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "233\n",
            "{'precision': [0.8331343531608582], 'recall': [0.7955954074859619], 'f1': [0.8139322400093079], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "234\n",
            "{'precision': [0.9480238556861877], 'recall': [0.8237448930740356], 'f1': [0.8815256357192993], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "235\n",
            "{'precision': [0.877419114112854], 'recall': [0.8121288418769836], 'f1': [0.8435124158859253], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "236\n",
            "{'precision': [0.9166378974914551], 'recall': [0.8074219822883606], 'f1': [0.8585706949234009], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "237\n",
            "{'precision': [0.845664918422699], 'recall': [0.7896928191184998], 'f1': [0.8167210221290588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "238\n",
            "{'precision': [0.8513699173927307], 'recall': [0.7964869737625122], 'f1': [0.823014497756958], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "239\n",
            "{'precision': [0.8364755511283875], 'recall': [0.7831461429595947], 'f1': [0.8089327812194824], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "240\n",
            "{'precision': [0.8351253867149353], 'recall': [0.789358913898468], 'f1': [0.811597466468811], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "241\n",
            "{'precision': [0.8526658415794373], 'recall': [0.7821943759918213], 'f1': [0.8159111738204956], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "242\n",
            "{'precision': [0.8462140560150146], 'recall': [0.7876067161560059], 'f1': [0.8158592581748962], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "243\n",
            "{'precision': [0.8348539471626282], 'recall': [0.8024797439575195], 'f1': [0.8183468580245972], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "244\n",
            "{'precision': [0.8086506724357605], 'recall': [0.7734387516975403], 'f1': [0.790652871131897], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "245\n",
            "{'precision': [0.8564646244049072], 'recall': [0.8386485576629639], 'f1': [0.8474629521369934], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "246\n",
            "{'precision': [0.835530698299408], 'recall': [0.8050153255462646], 'f1': [0.8199891448020935], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "247\n",
            "{'precision': [0.8317760825157166], 'recall': [0.794951319694519], 'f1': [0.8129469156265259], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "248\n",
            "{'precision': [0.8505644202232361], 'recall': [0.7975431680679321], 'f1': [0.8232009410858154], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "249\n",
            "{'precision': [0.8542441129684448], 'recall': [0.7972996830940247], 'f1': [0.8247901797294617], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "250\n",
            "{'precision': [0.8842110633850098], 'recall': [0.8215747475624084], 'f1': [0.8517429232597351], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "251\n",
            "{'precision': [0.8642513751983643], 'recall': [0.7830554842948914], 'f1': [0.821652352809906], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "252\n",
            "{'precision': [0.8359565734863281], 'recall': [0.782964825630188], 'f1': [0.8085933923721313], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "253\n",
            "{'precision': [0.8436365127563477], 'recall': [0.8362696170806885], 'f1': [0.8399369120597839], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "254\n",
            "{'precision': [0.8357858061790466], 'recall': [0.7943395972251892], 'f1': [0.8145357966423035], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "255\n",
            "{'precision': [0.8430403470993042], 'recall': [0.7792234420776367], 'f1': [0.8098766803741455], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "256\n",
            "{'precision': [0.8709394335746765], 'recall': [0.8153153657913208], 'f1': [0.8422099947929382], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "257\n",
            "{'precision': [0.86797696352005], 'recall': [0.8346284031867981], 'f1': [0.8509761095046997], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "258\n",
            "{'precision': [0.8422372937202454], 'recall': [0.7878744602203369], 'f1': [0.8141494393348694], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "259\n",
            "{'precision': [0.8566994071006775], 'recall': [0.821556031703949], 'f1': [0.83875972032547], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "260\n",
            "{'precision': [0.8544452786445618], 'recall': [0.7818261384963989], 'f1': [0.8165242075920105], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "261\n",
            "{'precision': [0.847904622554779], 'recall': [0.7956848740577698], 'f1': [0.8209651708602905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "262\n",
            "{'precision': [0.844537079334259], 'recall': [0.7980425357818604], 'f1': [0.8206318616867065], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "263\n",
            "{'precision': [0.8359077572822571], 'recall': [0.7797420024871826], 'f1': [0.8068486452102661], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "264\n",
            "{'precision': [0.9002997279167175], 'recall': [0.8082078099250793], 'f1': [0.8517717719078064], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "265\n",
            "{'precision': [0.8329352140426636], 'recall': [0.7995470762252808], 'f1': [0.8158997297286987], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "266\n",
            "{'precision': [0.8257172703742981], 'recall': [0.7845819592475891], 'f1': [0.8046241998672485], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "267\n",
            "{'precision': [0.8437942862510681], 'recall': [0.8109167218208313], 'f1': [0.8270288705825806], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "268\n",
            "{'precision': [0.8133454918861389], 'recall': [0.8198304176330566], 'f1': [0.8165751099586487], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "269\n",
            "{'precision': [0.8242831826210022], 'recall': [0.7860079407691956], 'f1': [0.8046906590461731], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "270\n",
            "{'precision': [0.8377926349639893], 'recall': [0.7871007323265076], 'f1': [0.8116559982299805], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "271\n",
            "{'precision': [0.8541097640991211], 'recall': [0.7992610931396484], 'f1': [0.825775682926178], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "272\n",
            "{'precision': [0.854511022567749], 'recall': [0.7879638671875], 'f1': [0.8198893070220947], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "273\n",
            "{'precision': [0.8239195346832275], 'recall': [0.7900657057762146], 'f1': [0.8066375255584717], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "274\n",
            "{'precision': [0.9017804861068726], 'recall': [0.8030791282653809], 'f1': [0.8495727181434631], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "275\n",
            "{'precision': [0.8436096906661987], 'recall': [0.7961483001708984], 'f1': [0.819192111492157], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "276\n",
            "{'precision': [0.8471308350563049], 'recall': [0.7824917435646057], 'f1': [0.813529372215271], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "277\n",
            "{'precision': [0.8452543616294861], 'recall': [0.7892440557479858], 'f1': [0.8162896037101746], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "278\n",
            "{'precision': [0.8602267503738403], 'recall': [0.8203896284103394], 'f1': [0.8398360013961792], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "279\n",
            "{'precision': [0.8435534238815308], 'recall': [0.7835429906845093], 'f1': [0.8124415874481201], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "280\n",
            "{'precision': [0.8226442337036133], 'recall': [0.7896319031715393], 'f1': [0.8058001399040222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "281\n",
            "{'precision': [0.8203268051147461], 'recall': [0.7910290360450745], 'f1': [0.8054115772247314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "282\n",
            "{'precision': [0.8594986796379089], 'recall': [0.7849118113517761], 'f1': [0.8205136656761169], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "283\n",
            "{'precision': [0.8386141657829285], 'recall': [0.8002235889434814], 'f1': [0.818969190120697], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "284\n",
            "{'precision': [0.8469079732894897], 'recall': [0.8011155724525452], 'f1': [0.8233755230903625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "285\n",
            "{'precision': [0.8678488731384277], 'recall': [0.8020810484886169], 'f1': [0.8336698412895203], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "286\n",
            "{'precision': [0.8358446955680847], 'recall': [0.7826671004295349], 'f1': [0.8083823323249817], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "287\n",
            "{'precision': [0.8421546816825867], 'recall': [0.8283084034919739], 'f1': [0.8351742029190063], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "288\n",
            "{'precision': [0.859136700630188], 'recall': [0.79840487241745], 'f1': [0.8276582360267639], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "289\n",
            "{'precision': [0.8232520818710327], 'recall': [0.7870374917984009], 'f1': [0.8047375679016113], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "290\n",
            "{'precision': [0.8394051194190979], 'recall': [0.7862344980239868], 'f1': [0.8119502663612366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "291\n",
            "{'precision': [0.8806594014167786], 'recall': [0.8182454109191895], 'f1': [0.8483060002326965], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "292\n",
            "{'precision': [0.8319838643074036], 'recall': [0.8099484443664551], 'f1': [0.820818305015564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "293\n",
            "{'precision': [0.879679799079895], 'recall': [0.8060433268547058], 'f1': [0.8412532806396484], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "294\n",
            "{'precision': [0.8721487522125244], 'recall': [0.8129857778549194], 'f1': [0.8415286540985107], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "295\n",
            "{'precision': [0.8509016633033752], 'recall': [0.7893785238265991], 'f1': [0.8189862370491028], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "296\n",
            "{'precision': [0.8456887006759644], 'recall': [0.7868982553482056], 'f1': [0.8152349591255188], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "297\n",
            "{'precision': [0.8323720693588257], 'recall': [0.7824677228927612], 'f1': [0.8066487908363342], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "298\n",
            "{'precision': [0.8486882448196411], 'recall': [0.7846507430076599], 'f1': [0.8154141306877136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "299\n",
            "{'precision': [0.8916017413139343], 'recall': [0.7989741563796997], 'f1': [0.8427504301071167], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "300\n",
            "{'precision': [0.7985392808914185], 'recall': [0.7732559442520142], 'f1': [0.7856943011283875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "301\n",
            "{'precision': [0.9031683206558228], 'recall': [0.7900261878967285], 'f1': [0.8428170680999756], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "302\n",
            "{'precision': [0.8313480615615845], 'recall': [0.7823154330253601], 'f1': [0.8060868382453918], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "303\n",
            "{'precision': [0.8375778198242188], 'recall': [0.7787516117095947], 'f1': [0.8070942163467407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "304\n",
            "{'precision': [0.8642290830612183], 'recall': [0.786247968673706], 'f1': [0.8233963251113892], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "305\n",
            "{'precision': [0.8323635458946228], 'recall': [0.779608428478241], 'f1': [0.8051226735115051], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "306\n",
            "{'precision': [0.807435929775238], 'recall': [0.7876625061035156], 'f1': [0.7974265813827515], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "307\n",
            "{'precision': [0.8350595235824585], 'recall': [0.8427485227584839], 'f1': [0.8388864398002625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "308\n",
            "{'precision': [0.8590570688247681], 'recall': [0.8013579845428467], 'f1': [0.8292050361633301], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "309\n",
            "{'precision': [0.8476729989051819], 'recall': [0.8069599270820618], 'f1': [0.8268156051635742], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "310\n",
            "{'precision': [0.8375697135925293], 'recall': [0.7874131202697754], 'f1': [0.8117173314094543], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "311\n",
            "{'precision': [0.8696091771125793], 'recall': [0.7961668968200684], 'f1': [0.8312690258026123], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "312\n",
            "{'precision': [0.8137404322624207], 'recall': [0.7867193818092346], 'f1': [0.8000018000602722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "313\n",
            "{'precision': [0.8653819561004639], 'recall': [0.8174809217453003], 'f1': [0.8407496809959412], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "314\n",
            "{'precision': [0.8493859171867371], 'recall': [0.7869937419891357], 'f1': [0.8170003294944763], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "315\n",
            "{'precision': [0.8692994713783264], 'recall': [0.7890359163284302], 'f1': [0.8272252678871155], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "316\n",
            "{'precision': [0.881394624710083], 'recall': [0.8148153424263], 'f1': [0.8467983603477478], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "317\n",
            "{'precision': [0.8630985021591187], 'recall': [0.7925953269004822], 'f1': [0.8263458013534546], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "318\n",
            "{'precision': [0.8508350253105164], 'recall': [0.7944706678390503], 'f1': [0.8216874003410339], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "319\n",
            "{'precision': [0.8094862699508667], 'recall': [0.7847966551780701], 'f1': [0.7969502806663513], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "320\n",
            "{'precision': [0.8597131371498108], 'recall': [0.8147644400596619], 'f1': [0.8366355299949646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "321\n",
            "{'precision': [0.8812101483345032], 'recall': [0.8237249851226807], 'f1': [0.8514984846115112], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "322\n",
            "{'precision': [0.8563777208328247], 'recall': [0.7912262082099915], 'f1': [0.8225138187408447], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "323\n",
            "{'precision': [0.8438817858695984], 'recall': [0.783841073513031], 'f1': [0.8127540946006775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "324\n",
            "{'precision': [0.8549935817718506], 'recall': [0.8032503128051758], 'f1': [0.8283146023750305], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "325\n",
            "{'precision': [0.852048933506012], 'recall': [0.7808973789215088], 'f1': [0.8149230480194092], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "326\n",
            "{'precision': [0.8759945631027222], 'recall': [0.7825261950492859], 'f1': [0.8266266584396362], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "327\n",
            "{'precision': [0.855878472328186], 'recall': [0.7984153628349304], 'f1': [0.8261489272117615], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "328\n",
            "{'precision': [0.9010440111160278], 'recall': [0.8255994915962219], 'f1': [0.8616734743118286], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "329\n",
            "{'precision': [0.8623673915863037], 'recall': [0.7872574329376221], 'f1': [0.8231024742126465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "330\n",
            "{'precision': [0.8340818881988525], 'recall': [0.7806264162063599], 'f1': [0.8064693212509155], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "331\n",
            "{'precision': [0.8655602335929871], 'recall': [0.7890142202377319], 'f1': [0.8255166411399841], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "332\n",
            "{'precision': [0.8658493757247925], 'recall': [0.8056226372718811], 'f1': [0.8346509337425232], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "333\n",
            "{'precision': [0.8511220216751099], 'recall': [0.7816557884216309], 'f1': [0.8149111866950989], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "334\n",
            "{'precision': [0.8632530570030212], 'recall': [0.7852429747581482], 'f1': [0.8224022388458252], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "335\n",
            "{'precision': [0.8838744163513184], 'recall': [0.7869227528572083], 'f1': [0.8325856924057007], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "336\n",
            "{'precision': [0.804746687412262], 'recall': [0.7644166946411133], 'f1': [0.7840633988380432], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "337\n",
            "{'precision': [0.8696156144142151], 'recall': [0.8391240239143372], 'f1': [0.8540977835655212], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "338\n",
            "{'precision': [0.9150410294532776], 'recall': [0.8446264863014221], 'f1': [0.8784249424934387], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "339\n",
            "{'precision': [0.8236933350563049], 'recall': [0.8159874081611633], 'f1': [0.8198222517967224], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "340\n",
            "{'precision': [0.840559184551239], 'recall': [0.7805052995681763], 'f1': [0.8094198703765869], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "341\n",
            "{'precision': [0.8576258420944214], 'recall': [0.7744126915931702], 'f1': [0.8138977885246277], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "342\n",
            "{'precision': [0.887644350528717], 'recall': [0.8245944380760193], 'f1': [0.8549585342407227], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "343\n",
            "{'precision': [0.8597478866577148], 'recall': [0.83121657371521], 'f1': [0.8452415466308594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "344\n",
            "{'precision': [0.8364183902740479], 'recall': [0.7907720804214478], 'f1': [0.8129549622535706], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "345\n",
            "{'precision': [0.8602914810180664], 'recall': [0.8072645664215088], 'f1': [0.8329349160194397], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "346\n",
            "{'precision': [0.825711190700531], 'recall': [0.7785002589225769], 'f1': [0.8014110326766968], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "347\n",
            "{'precision': [0.8621865510940552], 'recall': [0.8080441951751709], 'f1': [0.834237813949585], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "348\n",
            "{'precision': [0.8896626234054565], 'recall': [0.809053897857666], 'f1': [0.8474457263946533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "349\n",
            "{'precision': [0.8374814987182617], 'recall': [0.7865006327629089], 'f1': [0.8111908435821533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "350\n",
            "{'precision': [0.8741025328636169], 'recall': [0.8352648019790649], 'f1': [0.8542425036430359], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "351\n",
            "{'precision': [0.845848798751831], 'recall': [0.8068733811378479], 'f1': [0.8259015083312988], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "352\n",
            "{'precision': [0.8588689565658569], 'recall': [0.8090859651565552], 'f1': [0.8332345485687256], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "353\n",
            "{'precision': [0.8675348162651062], 'recall': [0.8256987929344177], 'f1': [0.8460999131202698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "354\n",
            "{'precision': [0.8341242074966431], 'recall': [0.7759721875190735], 'f1': [0.8039980530738831], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "355\n",
            "{'precision': [0.8771200180053711], 'recall': [0.8311216235160828], 'f1': [0.8535014986991882], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "356\n",
            "{'precision': [0.8533815741539001], 'recall': [0.7916253209114075], 'f1': [0.8213441967964172], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "357\n",
            "{'precision': [0.8147259950637817], 'recall': [0.7759160399436951], 'f1': [0.7948476076126099], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "358\n",
            "{'precision': [0.8512132167816162], 'recall': [0.7900773882865906], 'f1': [0.8195067048072815], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "359\n",
            "{'precision': [0.8406018614768982], 'recall': [0.8003457188606262], 'f1': [0.8199800252914429], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "360\n",
            "{'precision': [0.8903162479400635], 'recall': [0.8094024062156677], 'f1': [0.8479333519935608], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "361\n",
            "{'precision': [0.9123304486274719], 'recall': [0.8107923269271851], 'f1': [0.8585696816444397], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "362\n",
            "{'precision': [0.8710348606109619], 'recall': [0.7858721017837524], 'f1': [0.8262647986412048], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "363\n",
            "{'precision': [0.8552858233451843], 'recall': [0.799423336982727], 'f1': [0.8264116644859314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "364\n",
            "{'precision': [0.8461820483207703], 'recall': [0.7936128973960876], 'f1': [0.8190548419952393], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "365\n",
            "{'precision': [0.8645378947257996], 'recall': [0.7835214734077454], 'f1': [0.8220383524894714], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "366\n",
            "{'precision': [0.8770983219146729], 'recall': [0.8079837560653687], 'f1': [0.8411237001419067], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "367\n",
            "{'precision': [0.8580195903778076], 'recall': [0.7823852896690369], 'f1': [0.8184587955474854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "368\n",
            "{'precision': [0.832629382610321], 'recall': [0.7739770412445068], 'f1': [0.802232563495636], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "369\n",
            "{'precision': [0.8688889145851135], 'recall': [0.8076213598251343], 'f1': [0.8371356129646301], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "370\n",
            "{'precision': [0.8737411499023438], 'recall': [0.7938965559005737], 'f1': [0.8319073915481567], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "371\n",
            "{'precision': [0.8714473843574524], 'recall': [0.7913979291915894], 'f1': [0.8294958472251892], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "372\n",
            "{'precision': [0.8329483866691589], 'recall': [0.8019773960113525], 'f1': [0.8171694874763489], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "373\n",
            "{'precision': [0.8406413793563843], 'recall': [0.7915676236152649], 'f1': [0.815366804599762], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "374\n",
            "{'precision': [0.9406574368476868], 'recall': [0.8134191632270813], 'f1': [0.8724234104156494], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "375\n",
            "{'precision': [0.8363526463508606], 'recall': [0.825048565864563], 'f1': [0.8306620717048645], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "376\n",
            "{'precision': [0.8319380283355713], 'recall': [0.7845545411109924], 'f1': [0.8075518608093262], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "377\n",
            "{'precision': [0.8472805619239807], 'recall': [0.7943660616874695], 'f1': [0.8199705481529236], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "378\n",
            "{'precision': [0.8823687434196472], 'recall': [0.7822443246841431], 'f1': [0.8292953372001648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "379\n",
            "{'precision': [0.8293743133544922], 'recall': [0.7837392091751099], 'f1': [0.8059112429618835], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "380\n",
            "{'precision': [0.8573451638221741], 'recall': [0.7839670777320862], 'f1': [0.8190159201622009], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "381\n",
            "{'precision': [0.8577024936676025], 'recall': [0.8063594102859497], 'f1': [0.831238865852356], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "382\n",
            "{'precision': [0.8642394542694092], 'recall': [0.797055184841156], 'f1': [0.8292887806892395], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "383\n",
            "{'precision': [0.8796777725219727], 'recall': [0.7853124141693115], 'f1': [0.829820990562439], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "384\n",
            "{'precision': [0.8579221963882446], 'recall': [0.7887052893638611], 'f1': [0.8218590021133423], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "385\n",
            "{'precision': [0.8617916703224182], 'recall': [0.7803642749786377], 'f1': [0.8190591931343079], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "386\n",
            "{'precision': [0.8511146306991577], 'recall': [0.7959979772567749], 'f1': [0.8226341605186462], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "387\n",
            "{'precision': [0.8534098863601685], 'recall': [0.7833771109580994], 'f1': [0.8168953061103821], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "388\n",
            "{'precision': [0.8651294708251953], 'recall': [0.8352421522140503], 'f1': [0.8499231338500977], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "389\n",
            "{'precision': [0.8527490496635437], 'recall': [0.780134916305542], 'f1': [0.8148273825645447], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "390\n",
            "{'precision': [0.8579786419868469], 'recall': [0.8299930095672607], 'f1': [0.8437538743019104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "391\n",
            "{'precision': [0.9003851413726807], 'recall': [0.7859811186790466], 'f1': [0.8393024802207947], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "392\n",
            "{'precision': [0.8416716456413269], 'recall': [0.7781825065612793], 'f1': [0.8086828589439392], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "393\n",
            "{'precision': [0.9009038805961609], 'recall': [0.8701705932617188], 'f1': [0.8852705359458923], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "394\n",
            "{'precision': [0.8866270780563354], 'recall': [0.8030315637588501], 'f1': [0.8427613973617554], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "395\n",
            "{'precision': [0.844443142414093], 'recall': [0.8053550720214844], 'f1': [0.8244360685348511], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "396\n",
            "{'precision': [0.8476639986038208], 'recall': [0.7950348258018494], 'f1': [0.8205063939094543], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "397\n",
            "{'precision': [0.8688986301422119], 'recall': [0.7897281050682068], 'f1': [0.8274238109588623], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "398\n",
            "{'precision': [0.8676834106445312], 'recall': [0.7959043979644775], 'f1': [0.8302453756332397], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "399\n",
            "{'precision': [0.8518409729003906], 'recall': [0.7785937786102295], 'f1': [0.813572108745575], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "400\n",
            "{'precision': [0.833621621131897], 'recall': [0.7914912700653076], 'f1': [0.8120103478431702], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "401\n",
            "{'precision': [0.8597497344017029], 'recall': [0.7852280139923096], 'f1': [0.82080078125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "402\n",
            "{'precision': [0.8606894016265869], 'recall': [0.7892574667930603], 'f1': [0.823427140712738], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "403\n",
            "{'precision': [0.8687604069709778], 'recall': [0.7963675260543823], 'f1': [0.8309902548789978], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "404\n",
            "{'precision': [0.8367685079574585], 'recall': [0.7965832948684692], 'f1': [0.8161816000938416], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "405\n",
            "{'precision': [0.8759787082672119], 'recall': [0.8513269424438477], 'f1': [0.8634769320487976], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "406\n",
            "{'precision': [0.883387565612793], 'recall': [0.7861772775650024], 'f1': [0.8319523930549622], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "407\n",
            "{'precision': [0.8618587851524353], 'recall': [0.7791694402694702], 'f1': [0.8184307813644409], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "408\n",
            "{'precision': [0.865287184715271], 'recall': [0.7957260608673096], 'f1': [0.8290500640869141], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "409\n",
            "{'precision': [0.8812885284423828], 'recall': [0.8008449077606201], 'f1': [0.8391432166099548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "410\n",
            "{'precision': [0.8312140703201294], 'recall': [0.7942273616790771], 'f1': [0.812299907207489], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "411\n",
            "{'precision': [0.842491626739502], 'recall': [0.7976415157318115], 'f1': [0.8194533586502075], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.31.0)'}\n",
            "412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisions = bert_scores['precision']\n",
        "recalls = bert_scores['recall']\n",
        "f1s = bert_scores['f1']"
      ],
      "metadata": {
        "id": "LNko280tZvah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [CharacterScore](https://huggingface.co/spaces/evaluate-metric/character)\n",
        "> CharacTer is a character-level metric inspired by the translation edit rate (TER) metric. It is defined as the minimum number of character edits required to adjust a hypothesis, until it completely matches the reference, normalized by the length of the hypothesis sentence. CharacTer calculates the character level edit distance while performing the shift edit on word level. Unlike the strict matching criterion in TER, a hypothesis word is considered to match a reference word and could be shifted, if the edit distance between them is below a threshold value. The Levenshtein distance between the reference and the shifted hypothesis sequence is computed on the character level. In addition, the lengths of hypothesis sequences instead of reference sequences are used for normalizing the edit distance, which effectively counters the issue that shorter translations normally achieve lower TER."
      ],
      "metadata": {
        "id": "9ieEOOZLZHfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "character = evaluate.load(\"character\")"
      ],
      "metadata": {
        "id": "MOAtLq_5Xtqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "character_scores = character.compute(references=prompt_texts, predictions=summaries)"
      ],
      "metadata": {
        "id": "eSfaCE5qZcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_scores = character_scores['cer_scores']"
      ],
      "metadata": {
        "id": "Ro8c-Ww8ZnhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [NIST_MT](https://huggingface.co/spaces/evaluate-metric/nist_mt)\n",
        "> DARPA commissioned NIST to develop an MT evaluation facility based on the BLEU score. The official script used by NIST to compute BLEU and NIST score is mteval-14.pl. The main differences are:\n",
        "* BLEU uses geometric mean of the ngram overlaps, NIST uses arithmetic mean.\n",
        "* NIST has a different brevity penalty\n",
        "* NIST score from mteval-14.pl has a self-contained tokenizer (in the Hugging Face implementation we rely on NLTKs implementation of the NIST-specific tokenizer)"
      ],
      "metadata": {
        "id": "ZuYNhjSTaiOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "nist_mt = evaluate.load(\"nist_mt\")"
      ],
      "metadata": {
        "id": "ipIowOmJa9cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nist_scores = nist_mt.compute(preds=summaries, refs=prompt_texts)\n",
        "nist_mt_scores = nist_scores['nist_mt']"
      ],
      "metadata": {
        "id": "kM7AmsJlbJCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Charcut](https://huggingface.co/spaces/evaluate-metric/charcut_mt)\n",
        "> CharCut compares outputs of MT systems with reference translations. The matching algorithm is based on an iterative search for longest common substrings, combined with a length-based threshold that limits short and noisy character matches. As a similarity metric this is not new, but to the best of our knowledge it was never applied to highlighting and scoring of MT outputs. It has the neat effect of keeping character-based differences readable by humans"
      ],
      "metadata": {
        "id": "oRrdeX24bb2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "charcut = evaluate.load(\"charcut\")"
      ],
      "metadata": {
        "id": "XOC-r20Bb0ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = charcut.compute(references=prompt_texts, predictions=summaries)\n",
        "charcut_scores = results['charcut_mt']"
      ],
      "metadata": {
        "id": "SxL4dGtUciYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [ExactMatch](https://huggingface.co/spaces/evaluate-metric/exact_match)\n",
        "> A given predicted strings exact match score is 1 if it is the exact same as its reference string, and is 0 otherwise.\n",
        "* Example 1: The exact match score of prediction Happy Birthday! is 0, given its reference is Happy New Year!.\n",
        "* Example 2: The exact match score of prediction The Colour of Magic (1983) is 1, given its reference is also The Colour of Magic (1983).\n",
        "The exact match score of a set of predictions is the sum of all of the individual exact match scores in the set, divided by the total number of predictions in the set.\n",
        "* Example: The exact match score of the set {Example 1, Example 2} (above) is 0.5.\n",
        "\n"
      ],
      "metadata": {
        "id": "poNJBmiFczWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "exact_match_metric = load(\"exact_match\")"
      ],
      "metadata": {
        "id": "D-3l9DB3c_TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = exact_match_metric.compute(predictions=summaries, references=prompt_texts)\n",
        "exact_match_scores = results['exact_match']"
      ],
      "metadata": {
        "id": "0YeQKxkKdM64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [RougeScore](https://huggingface.co/spaces/evaluate-metric/rouge)\n",
        "\n",
        "> ROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics and a software package used for evaluating automatic summarization and machine translation software in natural language processing. The metrics compare an automatically produced summary or translation against a reference or a set of references (human-produced) summary or translation.\n",
        "Note that ROUGE is case insensitive, meaning that upper case letters are treated the same way as lower case letters."
      ],
      "metadata": {
        "id": "xW3oAAWCd6qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')"
      ],
      "metadata": {
        "id": "vDs2fzPxhyKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = rouge.compute(predictions=summaries, references=prompt_texts, use_aggregator=False)\n",
        "\n",
        "rouge1_scores = results['rouge1']\n",
        "rouge2_scores = results['rouge2']\n",
        "rougeL_scores = results['rougeL']\n",
        "rougeLsum_scores = results['rougeLsum']"
      ],
      "metadata": {
        "id": "n8wC8WYHiRg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [CometScore](https://huggingface.co/spaces/evaluate-metric/wer)\n",
        "\n",
        "\n",
        "> Crosslingual Optimized Metric for Evaluation of Translation (COMET) is an open-source framework used to train Machine Translation metrics that achieve high levels of correlation with different types of human judgments.\n",
        "\n",
        "*COMET takes 3 lists of strings as input: sources (a list of source sentences), predictions (a list of candidate translations) and references (a list of reference translations).*"
      ],
      "metadata": {
        "id": "NrnYmbGhd6jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "comet_metric = load('comet')"
      ],
      "metadata": {
        "id": "n-_nHknOnc8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = comet_metric.compute(predictions=summaries, references=prompt_questions, sources=prompt_texts)\n",
        "comet_scores = [round(v, 2) for v in results[\"scores\"]]"
      ],
      "metadata": {
        "id": "5zql-6WZojPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [MAUVE](https://huggingface.co/spaces/evaluate-metric/mauve)\n",
        "> MAUVE is a measure of the gap between neural text and human text. It is computed using the KullbackLeibler (KL) divergences between the two distributions of text in a quantized embedding space of a large language model. MAUVE can identify differences in quality arising from model sizes and decoding algorithms.\n",
        "\n"
      ],
      "metadata": {
        "id": "xuUlg0Dypdab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "mauve = load('mauve')"
      ],
      "metadata": {
        "id": "r4PcAPb_pkgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mauve_results = []\n",
        "\n",
        "for i in range(len(summaries)):\n",
        "  mauve_results.append(mauve.compute(predictions=[summaries[i]], references=[prompt_texts[i]]))"
      ],
      "metadata": {
        "id": "rakmHhoDpmvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mauve_scores = [item['mauve'] for item in mauve_results]"
      ],
      "metadata": {
        "id": "8kJ0_hWTp1zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [MeteorScore](https://huggingface.co/spaces/evaluate-metric/meteor)\n",
        "\n",
        "> METEOR (Metric for Evaluation of Translation with Explicit ORdering) is a machine translation evaluation metric, which is calculated based on the harmonic mean of precision and recall, with recall weighted more than precision.\n",
        "METEOR is based on a generalized concept of unigram matching between the machine-produced translation and human-produced reference translations. Unigrams can be matched based on their surface forms, stemmed forms, and meanings. Once all generalized unigram matches between the two strings have been found, METEOR computes a score for this matching using a combination of unigram-precision, unigram-recall, and a measure of fragmentation that is designed to directly capture how well-ordered the matched words in the machine translation are in relation to the reference.\n",
        "\n"
      ],
      "metadata": {
        "id": "K1elEqTfqXXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = evaluate.load('meteor')"
      ],
      "metadata": {
        "id": "0M5J4-hfqg9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meteor_scores = []\n",
        "\n",
        "for i in range(len(summaries)):\n",
        "  meteor_scores.append(meteor.compute(predictions=[summaries[i]], references=[prompt_texts[i]]))"
      ],
      "metadata": {
        "id": "PDmtVb7CqrVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meteor_scores = [item['meteor'] for item in meteor_scores]"
      ],
      "metadata": {
        "id": "jFmU9HRHrBCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [SariScore](https://huggingface.co/spaces/evaluate-metric/sari)\n",
        "\n",
        "\n",
        "> SARI (system output against references and against the input sentence) is a metric used for evaluating automatic text simplification systems.\n",
        "The metric compares the predicted simplified sentences against the reference and the source sentences. It explicitly measures the goodness of words that are added, deleted and kept by the system.\n",
        "\n",
        "SARI can be computed as:\n",
        "\n",
        "sari = ( F1_add + F1_keep + P_del) / 3\n",
        "\n",
        "where\n",
        "\n",
        "F1_add is the n-gram F1 score for add operations\n",
        "\n",
        "F1_keep is the n-gram F1 score for keep operations\n",
        "\n",
        "P_del is the n-gram precision score for delete operations\n",
        "\n",
        "The number of n grams, n, is equal to 4, as in the original paper.\n",
        "\n"
      ],
      "metadata": {
        "id": "imcJyPV2rHRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "sari = load(\"sari\")"
      ],
      "metadata": {
        "id": "spEXz2x4rlhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metric takes 3 inputs: sources (a list of source sentence strings), predictions (a list of predicted sentence strings) and references (a list of lists of reference sentence strings)"
      ],
      "metadata": {
        "id": "9GLZpKIKr2Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sari_scores = []\n",
        "for i in range(len(summaries)):\n",
        "  sari_scores.append(sari.compute(sources=prompt_texts, predictions=summaries, references=prompt_questions))\n",
        "\n",
        "sari_scores = [item['sari'] for item in sari_scores]"
      ],
      "metadata": {
        "id": "NyYZ8iJgrxo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SQUAD/CUAD TODO\n",
        "\n",
        "[CuadScore](https://huggingface.co/spaces/evaluate-metric/cuad)\n",
        "\n",
        "\n",
        "> This metric wraps the official scoring script for version 1 of the Contract Understanding Atticus Dataset (CUAD), which is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of important clauses that lawyers look for when reviewing contracts in connection with corporate transactions.\n",
        "The CUAD metric computes several scores: Exact Match, F1 score, Area Under the Precision-Recall Curve, Precision at 80% recall and Precision at 90% recall.\n",
        "\n"
      ],
      "metadata": {
        "id": "XJNgIm9qsT5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "cuad_metric = load(\"cuad\")"
      ],
      "metadata": {
        "id": "-bQLRvPltAkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The CUAD metric takes two inputs :**\n",
        "\n",
        "*predictions*, a list of question-answer dictionaries with the following key-values:\n",
        "\n",
        "* id: the id of the question-answer pair as given in the references.\n",
        "* prediction_text: a list of possible texts for the answer, as a list of strings depending on a threshold on the confidence probability of each prediction.\n",
        "\n",
        "*references*: a list of question-answer dictionaries with the following key-values:\n",
        "\n",
        "* id: the id of the question-answer pair (the same as above).\n",
        "answers: a dictionary in the CUAD dataset format with the following keys:\n",
        "* text: a list of possible texts for the answer, as a list of strings.\n",
        "answer_start: a list of start positions for the answer, as a list of ints.\n",
        "Note that answer_start values are not taken into account to compute the metric."
      ],
      "metadata": {
        "id": "6OBBEFzqtRme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [{'prediction_text': ['The seller:', 'The buyer/End-User: Shenzhen LOHAS Supply Chain Management Co., Ltd.'], 'id': 'LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Parties'}]\n",
        "references = [{'answers': {'answer_start': [143, 49], 'text': ['The seller:', 'The buyer/End-User: Shenzhen LOHAS Supply Chain Management Co., Ltd.']}, 'id': 'LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Parties'}]\n",
        "results = cuad_metric.compute(predictions=predictions, references=references)\n",
        "print(results)\n",
        "{'exact_match': 100.0, 'f1': 100.0, 'aupr': 0.0, 'prec_at_80_recall': 1.0, 'prec_at_90_recall': 1.0}"
      ],
      "metadata": {
        "id": "Q51UHN3VtLO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build the final dataset"
      ],
      "metadata": {
        "id": "iD7DJ9R3w3Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(columns = ['precision', 'recall', 'f1', 'cer_score', 'nist_mt_score', 'charcut_mt_score', 'exact_match_score',\\\n",
        "                                  'rouge1_score', 'rouge2_score', 'rougeL_score', 'rougeLsum_score', 'comet_score'\\\n",
        "                                  'mauve_score', 'meteor', 'sari', 'content', 'wording'], data=[])\n",
        "# all columns except wording and content are features\n",
        "# content and wording are target values\n",
        "# we gonna train a regression model to predict content and wording"
      ],
      "metadata": {
        "id": "5VgriN97w6qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['precision'] = precisions\n",
        "dataset['recall'] = recalls\n",
        "dataset['f1'] = f1s\n",
        "dataset['cer_score'] = cer_scores\n",
        "dataset['nist_mt_score'] = nist_mt_scores\n",
        "dataset['charcut_mt_score'] = charcut_scores\n",
        "dataset['exact_math_score'] = exact_match_scores\n",
        "dataset['rouge1'] = rouge1_scores\n",
        "dataset['rouge2'] = rouge2_scores\n",
        "dataset['rougeL'] = rougeL_scores\n",
        "dataset['rougeLsum'] = rougeLsum_scores\n",
        "dataset['rouge1'] = rouge1_scores\n",
        "dataset['comet_score'] = comet_scores\n",
        "dataset['mauve_score'] = mauve_scores\n",
        "dataset['meteor'] = meteor_scores\n",
        "dataset['sari'] = sari_scores\n",
        "dataset['content'] = combined_train_df['content']\n",
        "dataset['wording'] = combined_train_df['wording']"
      ],
      "metadata": {
        "id": "9CxRK8JexwQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}